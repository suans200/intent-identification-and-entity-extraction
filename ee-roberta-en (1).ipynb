{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9185769,"sourceType":"datasetVersion","datasetId":5552539}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForTokenClassification,\n    get_scheduler\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T05:48:53.779294Z","iopub.execute_input":"2024-08-24T05:48:53.779663Z","iopub.status.idle":"2024-08-24T05:48:56.912163Z","shell.execute_reply.started":"2024-08-24T05:48:53.779634Z","shell.execute_reply":"2024-08-24T05:48:56.911304Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/data-set1/indic-health-demo-main/Dataset/IHQID-WebMD/train.csv')[['question_english','disease_english','drug_english','treatment_english']]\ntest_df=pd.read_csv('/kaggle/input/data-set1/indic-health-demo-main/Dataset/IHQID-WebMD/test.csv')[['question_english','disease_english','drug_english','treatment_english']]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:56.914659Z","iopub.execute_input":"2024-08-24T05:48:56.915199Z","iopub.status.idle":"2024-08-24T05:48:56.966318Z","shell.execute_reply.started":"2024-08-24T05:48:56.915164Z","shell.execute_reply":"2024-08-24T05:48:56.965605Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:56.967451Z","iopub.execute_input":"2024-08-24T05:48:56.967803Z","iopub.status.idle":"2024-08-24T05:48:56.981886Z","shell.execute_reply.started":"2024-08-24T05:48:56.967769Z","shell.execute_reply":"2024-08-24T05:48:56.980977Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                    question_english      disease_english  \\\n0                   what is nystatin prescribed for?                  NaN   \n1  can douching after sex stop me from getting pr...             pregnant   \n2                    does percocet cause weight gain          weight gain   \n3  does 2 or 2 1/2 glasses of wine a day caues hi...  high blood pressure   \n4              can too much buttermilk cause thrush?               thrush   \n\n  drug_english treatment_english  \n0     nystatin               NaN  \n1          NaN               NaN  \n2     percocet               NaN  \n3          NaN               NaN  \n4          NaN               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_english</th>\n      <th>disease_english</th>\n      <th>drug_english</th>\n      <th>treatment_english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is nystatin prescribed for?</td>\n      <td>NaN</td>\n      <td>nystatin</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>can douching after sex stop me from getting pr...</td>\n      <td>pregnant</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>does percocet cause weight gain</td>\n      <td>weight gain</td>\n      <td>percocet</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>does 2 or 2 1/2 glasses of wine a day caues hi...</td>\n      <td>high blood pressure</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>can too much buttermilk cause thrush?</td>\n      <td>thrush</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from fuzzywuzzy import fuzz","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:56.983325Z","iopub.execute_input":"2024-08-24T05:48:56.983723Z","iopub.status.idle":"2024-08-24T05:48:56.992215Z","shell.execute_reply.started":"2024-08-24T05:48:56.983689Z","shell.execute_reply":"2024-08-24T05:48:56.991206Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_common_sequence(tokenized_sentence,tokenized_entity,entity,tag_list):\n    common_sequence={\n        'similarity':0.0,\n        'start_index':-1,\n        'end_index':-1\n    }\n    target_len=len(tokenized_entity)\n    sentence_len=len(tokenized_sentence)\n    for i in range(sentence_len-target_len):\n        fuzz_ratio=fuzz.ratio(tokenized_sentence[i:i+target_len],tokenized_entity)\n        if fuzz_ratio>=80 and common_sequence['similarity']<fuzz_ratio:\n            common_sequence['similarity']=fuzz_ratio\n            common_sequence['start_index']=i\n            common_sequence['end_index']=i+target_len-1\n        fuzz_ratio=fuzz.ratio(tokenized_sentence[i:i+target_len-1],tokenized_entity)\n        if fuzz_ratio>=80 and common_sequence['similarity']<fuzz_ratio:\n            common_sequence['similarity']=fuzz_ratio\n            common_sequence['start_index']=i;\n            common_sequence['end_index']=i+target_len-1\n    tag_list[common_sequence['start_index']]=\"B-\"+entity\n    for i in range(common_sequence['start_index']+1,common_sequence['end_index']):\n        tag_list[i]=\"I-\"+entity\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:56.995228Z","iopub.execute_input":"2024-08-24T05:48:56.995553Z","iopub.status.idle":"2024-08-24T05:48:57.005343Z","shell.execute_reply.started":"2024-08-24T05:48:56.995525Z","shell.execute_reply":"2024-08-24T05:48:57.004425Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import  word_tokenize\nimport math","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:57.006452Z","iopub.execute_input":"2024-08-24T05:48:57.006813Z","iopub.status.idle":"2024-08-24T05:48:57.703193Z","shell.execute_reply.started":"2024-08-24T05:48:57.006779Z","shell.execute_reply":"2024-08-24T05:48:57.702348Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for i in range(len(train_df)):\n    tokenised_sentence=word_tokenize(train_df.loc[i,'question_english'].lower())\n    tag_list=['O' for i in tokenised_sentence]\n    if type(train_df.loc[i,'disease_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in train_df.loc[i,'disease_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"disease\",tag_list)\n    else:\n        assert(math.isnan(train_df.loc[i,'disease_english']))\n    if type(train_df.loc[i,'drug_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in train_df.loc[i,'drug_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"drug\",tag_list)\n    else:\n        assert(math.isnan(train_df.loc[i,'drug_english']))\n    if type(train_df.loc[i,'treatment_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in train_df.loc[i,'treatment_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"treatment\",tag_list)\n    else:\n        assert(math.isnan(train_df.loc[i,'treatment_english']))\n    train_df.loc[i,'question_english']=str(tokenised_sentence)\n    train_df.loc[i,'tag_english']=str(tag_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:48:57.704412Z","iopub.execute_input":"2024-08-24T05:48:57.704799Z","iopub.status.idle":"2024-08-24T05:48:59.382788Z","shell.execute_reply.started":"2024-08-24T05:48:57.704766Z","shell.execute_reply":"2024-08-24T05:48:59.381896Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i in range(len(test_df)):\n    tokenised_sentence=word_tokenize(test_df.loc[i,'question_english'].lower())\n    tag_list=['O' for i in tokenised_sentence]\n    if type(test_df.loc[i,'disease_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in test_df.loc[i,'disease_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"disease\",tag_list)\n    else:\n        assert(math.isnan(test_df.loc[i,'disease_english']))\n    if type(test_df.loc[i,'drug_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in test_df.loc[i,'drug_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"drug\",tag_list)\n    else:\n        assert(math.isnan(test_df.loc[i,'drug_english']))\n    if type(test_df.loc[i,'treatment_english']) is not float:\n        tokenized_disease=[word_tokenize(j.lower()) for j in test_df.loc[i,'treatment_english'].split(',')]\n        for k in tokenized_disease:\n            get_common_sequence(tokenised_sentence,k,\"treatment\",tag_list)\n    else:\n        assert(math.isnan(test_df.loc[i,'treatment_english']))\n    test_df.loc[i,'question_english']=str(tokenised_sentence)\n    test_df.loc[i,'tag_english']=str(tag_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:14.716850Z","iopub.execute_input":"2024-08-24T05:49:14.717222Z","iopub.status.idle":"2024-08-24T05:49:15.290705Z","shell.execute_reply.started":"2024-08-24T05:49:14.717194Z","shell.execute_reply":"2024-08-24T05:49:15.289896Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:22.367177Z","iopub.execute_input":"2024-08-24T05:49:22.367885Z","iopub.status.idle":"2024-08-24T05:49:22.381154Z","shell.execute_reply.started":"2024-08-24T05:49:22.367853Z","shell.execute_reply":"2024-08-24T05:49:22.380108Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                    question_english      disease_english  \\\n0  ['what', 'is', 'nystatin', 'prescribed', 'for'...                  NaN   \n1  ['can', 'douching', 'after', 'sex', 'stop', 'm...             pregnant   \n2    ['does', 'percocet', 'cause', 'weight', 'gain']          weight gain   \n3  ['does', '2', 'or', '2', '1/2', 'glasses', 'of...  high blood pressure   \n4  ['can', 'too', 'much', 'buttermilk', 'cause', ...               thrush   \n\n  drug_english treatment_english  \\\n0     nystatin               NaN   \n1          NaN               NaN   \n2     percocet               NaN   \n3          NaN               NaN   \n4          NaN               NaN   \n\n                                         tag_english  \n0                ['O', 'O', 'B-drug', 'O', 'O', 'O']  \n1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-di...  \n2             ['O', 'B-drug', 'O', 'O', 'B-disease']  \n3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n4        ['O', 'O', 'O', 'O', 'O', 'B-disease', 'O']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_english</th>\n      <th>disease_english</th>\n      <th>drug_english</th>\n      <th>treatment_english</th>\n      <th>tag_english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['what', 'is', 'nystatin', 'prescribed', 'for'...</td>\n      <td>NaN</td>\n      <td>nystatin</td>\n      <td>NaN</td>\n      <td>['O', 'O', 'B-drug', 'O', 'O', 'O']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['can', 'douching', 'after', 'sex', 'stop', 'm...</td>\n      <td>pregnant</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-di...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['does', 'percocet', 'cause', 'weight', 'gain']</td>\n      <td>weight gain</td>\n      <td>percocet</td>\n      <td>NaN</td>\n      <td>['O', 'B-drug', 'O', 'O', 'B-disease']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['does', '2', 'or', '2', '1/2', 'glasses', 'of...</td>\n      <td>high blood pressure</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['can', 'too', 'much', 'buttermilk', 'cause', ...</td>\n      <td>thrush</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'B-disease', 'O']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def convert_string(string):\n    special_remove=string.replace('[','').replace(']','').replace('\"','').replace(\"'\", '')\n    split_str=special_remove.split(',')\n    return [item.strip() for item in split_str]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:22.690239Z","iopub.execute_input":"2024-08-24T05:49:22.690665Z","iopub.status.idle":"2024-08-24T05:49:22.696873Z","shell.execute_reply.started":"2024-08-24T05:49:22.690632Z","shell.execute_reply":"2024-08-24T05:49:22.695729Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df['question_english']=train_df['question_english'].apply(convert_string)\ntrain_df['tag_english']=train_df['tag_english'].apply(convert_string)\ntest_df['question_english']=test_df['question_english'].apply(convert_string)\ntest_df['tag_english']=test_df['tag_english'].apply(convert_string)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:22.933579Z","iopub.execute_input":"2024-08-24T05:49:22.933943Z","iopub.status.idle":"2024-08-24T05:49:22.949581Z","shell.execute_reply.started":"2024-08-24T05:49:22.933915Z","shell.execute_reply":"2024-08-24T05:49:22.948708Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"label__ = {\n    'O': 0,\n    'B-treatment': 1,\n    'I-treatment': 2,\n    'B-disease': 3,\n    'I-disease': 4,\n    'B-drug': 5,\n    'I-drug': 6\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:23.214452Z","iopub.execute_input":"2024-08-24T05:49:23.214825Z","iopub.status.idle":"2024-08-24T05:49:23.219736Z","shell.execute_reply.started":"2024-08-24T05:49:23.214797Z","shell.execute_reply":"2024-08-24T05:49:23.218614Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice='cuda' if torch.cuda.is_available() else 'cpu' \ndevice","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:23.455524Z","iopub.execute_input":"2024-08-24T05:49:23.456326Z","iopub.status.idle":"2024-08-24T05:49:23.518482Z","shell.execute_reply.started":"2024-08-24T05:49:23.456288Z","shell.execute_reply":"2024-08-24T05:49:23.517454Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"model_checkpoint = \"roberta-base\"\n\nhyper_parameters = {\n    'batch_size': 8,\n    'lr': 3e-5,\n    'epochs': 10\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:23.713221Z","iopub.execute_input":"2024-08-24T05:49:23.713562Z","iopub.status.idle":"2024-08-24T05:49:23.718148Z","shell.execute_reply.started":"2024-08-24T05:49:23.713535Z","shell.execute_reply":"2024-08-24T05:49:23.717269Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def clean_list(lst):\n    return [item for item in lst if item.strip()]\ntrain_df['question_english']=train_df['question_english'].apply(clean_list)\ntest_df['question_english']=test_df['question_english'].apply(clean_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:23.909857Z","iopub.execute_input":"2024-08-24T05:49:23.910552Z","iopub.status.idle":"2024-08-24T05:49:23.918662Z","shell.execute_reply.started":"2024-08-24T05:49:23.910521Z","shell.execute_reply":"2024-08-24T05:49:23.917729Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer=RobertaTokenizerFast.from_pretrained(model_checkpoint,add_prefix_space=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:24.114684Z","iopub.execute_input":"2024-08-24T05:49:24.115360Z","iopub.status.idle":"2024-08-24T05:49:24.415799Z","shell.execute_reply.started":"2024-08-24T05:49:24.115330Z","shell.execute_reply":"2024-08-24T05:49:24.414998Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# def labelling(question,tag):\n#     question = \" \".join(question)\n#     tokenized_input = tokenizer(question, truncation=True, padding='max_length', is_split_into_words=False)\n#     word_ids = tokenized_input.word_ids()\n#     for i, labels in enumerate(word_ids):\n#         if labels is None:\n#             word_ids[i] = 7\n#         else:\n#             word_ids[i] = label_1[tag[labels]]\n#     tokenized_input[\"labels\"] = word_ids\n#     return tokenized_input\ndef process_queries(question, tag): \n    \n    tokenized_input = tokenizer(question, truncation=True, padding='max_length', is_split_into_words=True)\n    word_ids = tokenized_input.word_ids()\n    j=1;\n    for i, label in enumerate(word_ids):\n        if label is None:\n            word_ids[i] = 7\n        else:\n            word_ids[i] = label__[tag[label]]\n            \n    tokenized_input[\"labels\"] = word_ids\n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:24.417220Z","iopub.execute_input":"2024-08-24T05:49:24.417526Z","iopub.status.idle":"2024-08-24T05:49:24.424090Z","shell.execute_reply.started":"2024-08-24T05:49:24.417500Z","shell.execute_reply":"2024-08-24T05:49:24.423209Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"encoded_input_train = {\n    'input_ids': [],\n    'attention_mask': [],\n    'tags_english': []\n}\nfor index in range(len(train_df['question_english'])):\n    process_output = process_queries(train_df.loc[index,'question_english'], train_df.loc[index,'tag_english'])\n    encoded_input_train['input_ids'].append(process_output['input_ids'])\n    encoded_input_train['attention_mask'].append(process_output['attention_mask'])\n    encoded_input_train['tags_english'].append(process_output['labels'])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:24.470144Z","iopub.execute_input":"2024-08-24T05:49:24.470435Z","iopub.status.idle":"2024-08-24T05:49:24.755084Z","shell.execute_reply.started":"2024-08-24T05:49:24.470404Z","shell.execute_reply":"2024-08-24T05:49:24.754225Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"encoded_input_test = {\n    'input_ids': [],\n    'attention_mask': [],\n    'tags_english': []\n}\nfor index in range(len(test_df['question_english'])):\n    process_output = process_queries(test_df.loc[index,'question_english'], test_df.loc[index,'tag_english'])\n    encoded_input_test['input_ids'].append(process_output['input_ids'])\n    encoded_input_test['attention_mask'].append(process_output['attention_mask'])\n    encoded_input_test['tags_english'].append(process_output['labels'])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:24.756582Z","iopub.execute_input":"2024-08-24T05:49:24.756897Z","iopub.status.idle":"2024-08-24T05:49:24.859393Z","shell.execute_reply.started":"2024-08-24T05:49:24.756871Z","shell.execute_reply":"2024-08-24T05:49:24.858700Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from torch.optim import AdamW\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:24.879681Z","iopub.execute_input":"2024-08-24T05:49:24.880280Z","iopub.status.idle":"2024-08-24T05:49:24.884611Z","shell.execute_reply.started":"2024-08-24T05:49:24.880243Z","shell.execute_reply":"2024-08-24T05:49:24.883747Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(\n    TensorDataset(\n        torch.tensor(encoded_input_train['input_ids']).to(device),\n        torch.tensor(encoded_input_train['attention_mask']).to(device),\n        torch.tensor(encoded_input_train['tags_english']).to(device)\n    ),\n    batch_size=hyper_parameters['batch_size']\n)\ntest_dataloader = DataLoader(\n    TensorDataset(\n        torch.tensor(encoded_input_test['input_ids']).to(device),\n        torch.tensor(encoded_input_test['attention_mask']).to(device),\n        torch.tensor(encoded_input_test['tags_english']).to(device)\n    ),\n    batch_size=hyper_parameters['batch_size']\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:25.078596Z","iopub.execute_input":"2024-08-24T05:49:25.078944Z","iopub.status.idle":"2024-08-24T05:49:25.696603Z","shell.execute_reply.started":"2024-08-24T05:49:25.078918Z","shell.execute_reply":"2024-08-24T05:49:25.695754Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = RobertaForTokenClassification.from_pretrained(\n    model_checkpoint,\n    num_labels=len(label__) + 1\n)\nmodel.to(device)\n\noptimizer = AdamW(\n    model.parameters(),\n    lr=hyper_parameters['lr']\n)\n\nlr_scheduler = get_scheduler(\n  \"linear\",\n  optimizer=optimizer,\n  num_warmup_steps=0,\n  num_training_steps=hyper_parameters['epochs'] * len(train_dataloader)\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:25.698163Z","iopub.execute_input":"2024-08-24T05:49:25.698467Z","iopub.status.idle":"2024-08-24T05:49:26.801328Z","shell.execute_reply.started":"2024-08-24T05:49:25.698441Z","shell.execute_reply":"2024-08-24T05:49:26.800444Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.train()\n\nupdater = tqdm(range(hyper_parameters['epochs']))\nfor epoch in updater:\n    total_train_loss = 0.0\n    for batch in train_dataloader:\n        \n        optimizer.zero_grad()\n        inputs = {\n            'input_ids': batch[0],\n            'attention_mask': batch[1],\n            'labels': batch[2],\n        }\n        \n        outputs = model(**inputs)\n        \n        loss = outputs.loss\n        loss.backward()\n        \n        optimizer.step()\n        lr_scheduler.step()\n        \n        total_train_loss += loss.item()\n    \n    print(\"Epoch:\", epoch + 1, \" - Training Loss:\", round(total_train_loss / len(train_dataloader), 4))\n\n\n# Didn't have much time to implement early stopping. So, saving the model at the end of all epochs.\ntorch.save(model.state_dict(), f'ee_rob_en.model')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T05:49:26.802553Z","iopub.execute_input":"2024-08-24T05:49:26.803021Z","iopub.status.idle":"2024-08-24T06:00:46.934575Z","shell.execute_reply.started":"2024-08-24T05:49:26.802994Z","shell.execute_reply":"2024-08-24T06:00:46.933735Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":" 10%|█         | 1/10 [01:07<10:10, 67.86s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1  - Training Loss: 0.1088\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [02:15<09:02, 67.83s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2  - Training Loss: 0.015\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [03:23<07:55, 67.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3  - Training Loss: 0.0111\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [04:31<06:47, 67.92s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4  - Training Loss: 0.0094\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [05:39<05:39, 67.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 5  - Training Loss: 0.0079\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [06:47<04:31, 67.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 6  - Training Loss: 0.0066\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [07:55<03:23, 67.92s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 7  - Training Loss: 0.0058\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [09:03<02:15, 67.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 8  - Training Loss: 0.0052\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [10:11<01:07, 67.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 9  - Training Loss: 0.0047\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [11:19<00:00, 67.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 10  - Training Loss: 0.0044\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\n\nprediction = []\ngold_label = []\n\nextra_appended_tokens = 0\n\nfor indexer, batch in enumerate(test_dataloader):\n\n    inputs = {\n        'input_ids': batch[0],\n        'attention_mask': batch[1],\n        'labels': batch[2],\n    }\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n\n    gold_label_cpu = inputs['labels'].cpu().numpy()\n    logits_vector = outputs.logits.detach().cpu().numpy()\n\n    assert(len(gold_label_cpu) == len(logits_vector))\n\n    for index in range(len(logits_vector)):\n        prediction_vector = []\n        for iterator__ in logits_vector[index].argmax(axis=1):\n            if iterator__ != 7:\n                prediction_vector.append(iterator__)\n                prediction.append(iterator__)\n        \n        gold_label_vector = []\n        for iterator__ in gold_label_cpu[index]:\n            if iterator__ != 7:\n                gold_label_vector.append(iterator__)\n                gold_label.append(iterator__)\n        \n        # There are some cases (only observed once) when there was one mismatch in vector of gold label and prediction\n        # To overcome that, for each tokenized\n        while len(gold_label) < len(prediction):\n            extra_appended_tokens += 1\n            gold_label.append(0)\n        \n        while len(prediction) < len(gold_label):\n            extra_appended_tokens += 1\n            prediction.append(0)\n\nprint(\"Number of extra appended tokens : \", extra_appended_tokens)\nprint(classification_report(gold_label, prediction))","metadata":{"execution":{"iopub.status.busy":"2024-08-24T06:01:02.762652Z","iopub.execute_input":"2024-08-24T06:01:02.763494Z","iopub.status.idle":"2024-08-24T06:01:09.729302Z","shell.execute_reply.started":"2024-08-24T06:01:02.763461Z","shell.execute_reply":"2024-08-24T06:01:09.728327Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Number of extra appended tokens :  0\n              precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96      2546\n           1       0.53      0.70      0.60        91\n           2       0.00      0.00      0.00        17\n           3       0.68      0.84      0.75       243\n           4       1.00      0.05      0.09        21\n           5       0.80      0.85      0.82       243\n           6       0.00      0.00      0.00        14\n\n    accuracy                           0.91      3175\n   macro avg       0.57      0.48      0.46      3175\nweighted avg       0.91      0.91      0.91      3175\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}